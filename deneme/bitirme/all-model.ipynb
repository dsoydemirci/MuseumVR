{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_curve, auc,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, cohen_kappa_score, f1_score, roc_auc_score\n",
    "from pandas.plotting import table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vs30(m/s)</th>\n",
       "      <th>EBD(m)</th>\n",
       "      <th>Predomninant_frequency</th>\n",
       "      <th>H/V_ratio</th>\n",
       "      <th>Building_damage_situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720</td>\n",
       "      <td>15</td>\n",
       "      <td>5,36</td>\n",
       "      <td>3,4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>546</td>\n",
       "      <td>22</td>\n",
       "      <td>1,44</td>\n",
       "      <td>3,4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>520</td>\n",
       "      <td>1,43</td>\n",
       "      <td>5,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>521</td>\n",
       "      <td>33</td>\n",
       "      <td>5,60</td>\n",
       "      <td>3,9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>238</td>\n",
       "      <td>146</td>\n",
       "      <td>5,00</td>\n",
       "      <td>6,6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Vs30(m/s) EBD(m) Predomninant_frequency H/V_ratio Building_damage_situation\n",
       "1       720     15                   5,36       3,4                         0\n",
       "2       546     22                   1,44       3,4                         0\n",
       "3       315    520                   1,43       5,9                         1\n",
       "4       521     33                   5,60       3,9                         0\n",
       "5       238    146                   5,00       6,6                         1"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"Station_ID\",\"Location\",\"Longitude\",\"Latitude\",\"Vs30(m/s)\",\"EBD(m)\",\"Predomninant_frequency\",\"H/V_ratio\",\"Building_damage_situation\"]\n",
    "\n",
    "df = pd.read_csv('data.csv', names=column_names)\n",
    "df = df.drop(0)\n",
    "df = df.drop(columns=[\"Station_ID\",\"Location\",\"Longitude\",\"Latitude\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Vs30(m/s)</th>\n",
       "      <th>EBD(m)</th>\n",
       "      <th>Predomninant_frequency</th>\n",
       "      <th>H/V_ratio</th>\n",
       "      <th>Building_damage_situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36,62062</td>\n",
       "      <td>37,01184</td>\n",
       "      <td>720</td>\n",
       "      <td>15</td>\n",
       "      <td>5,36</td>\n",
       "      <td>3,4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36,573771</td>\n",
       "      <td>36,930889</td>\n",
       "      <td>546</td>\n",
       "      <td>22</td>\n",
       "      <td>1,44</td>\n",
       "      <td>3,4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36,648373</td>\n",
       "      <td>37,09933</td>\n",
       "      <td>315</td>\n",
       "      <td>520</td>\n",
       "      <td>1,43</td>\n",
       "      <td>5,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>36,670482</td>\n",
       "      <td>37,128525</td>\n",
       "      <td>521</td>\n",
       "      <td>33</td>\n",
       "      <td>5,60</td>\n",
       "      <td>3,9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>36,14766</td>\n",
       "      <td>36,58801</td>\n",
       "      <td>238</td>\n",
       "      <td>146</td>\n",
       "      <td>5,00</td>\n",
       "      <td>6,6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location  Longitude   Latitude Vs30(m/s) EBD(m) Predomninant_frequency  \\\n",
       "1         2   36,62062   37,01184       720     15                   5,36   \n",
       "2         0  36,573771  36,930889       546     22                   1,44   \n",
       "3         1  36,648373   37,09933       315    520                   1,43   \n",
       "4         3  36,670482  37,128525       521     33                   5,60   \n",
       "5        13   36,14766   36,58801       238    146                   5,00   \n",
       "\n",
       "  H/V_ratio  Building_damage_situation  \n",
       "1       3,4                          0  \n",
       "2       3,4                          0  \n",
       "3       5,9                          1  \n",
       "4       3,9                          0  \n",
       "5       6,6                          1  "
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_features = [\"Location\",\"Building_damage_situation\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in categoric_features:\n",
    "    df[column] = le.fit_transform(df[column]) \n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into test,  validation and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location                     30\n",
      "Longitude                    30\n",
      "Latitude                     30\n",
      "Vs30(m/s)                    30\n",
      "EBD(m)                       30\n",
      "Predomninant_frequency       30\n",
      "H/V_ratio                    30\n",
      "Building_damage_situation    30\n",
      "dtype: int64 Location                     14\n",
      "Longitude                    14\n",
      "Latitude                     14\n",
      "Vs30(m/s)                    14\n",
      "EBD(m)                       14\n",
      "Predomninant_frequency       14\n",
      "H/V_ratio                    14\n",
      "Building_damage_situation    14\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Landa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.array_split(df.sample(frac=1),  [int(0.7*len(df))])\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = ['Location','Longitude','Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(df, oversample):\n",
    "    \n",
    "    df = df.drop(columns=unwanted_columns)\n",
    "    X = df[df.columns[:-1]].values\n",
    "    y = df[df.columns[-1]].values\n",
    "    \n",
    "    X = np.array([[float(str(val).replace(',', '.')) for val in row] for row in X])\n",
    "    \n",
    "    if oversample:\n",
    "        print(df['Building_damage_situation'].value_counts())\n",
    "        ros = RandomOverSampler()\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "        print('0   ', len(X), '\\n1   ', len(y))\n",
    "        \n",
    "    data = pd.DataFrame(np.hstack((X, np.reshape(y, (-1, 1)))), columns=df.columns)\n",
    "    df.head()\n",
    "    return data, X, y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Location', 'Longitude', 'Latitude'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[818], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train, X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mscale_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moversample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test, X_test, y_test \u001b[38;5;241m=\u001b[39m scale_dataset(test, oversample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[817], line 3\u001b[0m, in \u001b[0;36mscale_dataset\u001b[1;34m(df, oversample)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscale_dataset\u001b[39m(df, oversample):\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munwanted_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     X \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\Landa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Landa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Landa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Landa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Location', 'Longitude', 'Latitude'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train, X_train, y_train = scale_dataset(train, oversample= False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred, y_pred_prob):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    f1_score_value = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'F1 Score': f1_score_value,\n",
    "        'Kappa': kappa,\n",
    "        'AUC': roc_auc\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_train_result(model, X_test, y_test, is_nn=False):\n",
    "    y_pred = model.predict(X_test)\n",
    "    if is_nn:\n",
    "        y_pred_prob = y_pred[:, 0]\n",
    "    else:\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plt.subplot(1, 3, 2)\n",
    "    cm = confusion_matrix(y_test, y_pred_binary)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    # Metric Scores Table\n",
    "    plt.subplot(1, 3, 3)\n",
    "    scores = get_scores(y_test, y_pred_binary, y_pred_prob)\n",
    "    scores_df = pd.DataFrame(list(scores.items()), columns=['Metric', 'Score'])\n",
    "    plt.axis('off')  # Sadece tablo görüntülenir, eksenler kapatılır\n",
    "    plt.table(cellText=scores_df.values, colLabels=scores_df.columns, cellLoc='center', loc='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy = 0.0\n",
    "best_accuracy_model = None\n",
    "best_k_value = None\n",
    "\n",
    "for i in range(1, 10):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    temp_model = knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = temp_model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    ## Cross validation test\n",
    "    scores = cross_val_score(knn_model,X_test,y_test,cv=5)\n",
    "    print(\"cross validate score for k={0} \".format(i),scores.mean())\n",
    "    \n",
    "    if accuracy > highest_accuracy:\n",
    "        highest_accuracy = accuracy\n",
    "        best_accuracy_model = temp_model\n",
    "        best_k_value = i\n",
    "        \n",
    "print(\"Model resut with best k={} without cross validation: \".format(best_k_value) , highest_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_result(best_accuracy_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy_nb = 0.0\n",
    "best_accuracy_model_nb = None\n",
    "\n",
    "for var_smoothing in [1e-9, 1e-8, 1e-7]:\n",
    "    nb_model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    temp_model_nb = nb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_nb = temp_model_nb.predict(X_test)\n",
    "    \n",
    "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "    \n",
    "    ## Cross validation test\n",
    "    scores = cross_val_score(nb_model,X_test,y_test,cv=4)\n",
    "    print(\"cross validate score for smoothing={0} \".format(var_smoothing),scores.mean())\n",
    "    \n",
    "    if accuracy_nb > highest_accuracy_nb:\n",
    "        highest_accuracy_nb = accuracy_nb\n",
    "        best_accuracy_model_nb = temp_model_nb\n",
    "        \n",
    "print(\"Model resut with best smoothing={} without cross validation: \".format(var_smoothing) , highest_accuracy_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_result(best_accuracy_model_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy_lr = 0.0\n",
    "best_accuracy_model_lr = None\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    lr_model = LogisticRegression(C=C, random_state=42,solver='liblinear')\n",
    "    temp_model_lr = lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_lr = temp_model_lr.predict(X_test)\n",
    "    \n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "     ## Cross validation test\n",
    "    scores = cross_val_score(lr_model,X_test,y_test,cv=4)\n",
    "    print(\"cross validate score for C={0} \".format(C),scores.mean())\n",
    "    \n",
    "    \n",
    "    if accuracy_lr > highest_accuracy_lr:\n",
    "        highest_accuracy_lr = accuracy_lr\n",
    "        best_accuracy_model_lr = temp_model_lr\n",
    "        \n",
    "print(\"Model resut with best C={} without cross validation: \".format(C) , highest_accuracy_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_result(best_accuracy_model_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy_svm = 0.0\n",
    "best_accuracy_model_svm = None\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm_model = SVC(C=C, probability=True, random_state=42,kernel='rbf')\n",
    "    temp_model_svm = svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_svm = temp_model_svm.predict(X_test)\n",
    "    \n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    \n",
    "    ## Cross validation test\n",
    "    scores = cross_val_score(svm_model,X_test,y_test,cv=4)\n",
    "    print(\"cross validate score for C={0} \".format(C),scores.mean())\n",
    "    \n",
    "    \n",
    "    if accuracy_svm > highest_accuracy_svm:\n",
    "        highest_accuracy_svm = accuracy_svm\n",
    "        best_accuracy_model_svm = temp_model_svm\n",
    "        \n",
    "print(\"Model resut with best C={} without cross validation: \".format(C) , highest_accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_result(best_accuracy_model_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy_tree = 0.0\n",
    "best_accuracy_model_tree = None\n",
    "best_value = 0\n",
    "\n",
    "for max_depth in [None, 5, 10, 15]:\n",
    "    tree_model = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "    temp_model_tree = tree_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_tree = temp_model_tree.predict(X_test)\n",
    "    \n",
    "    accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "    \n",
    "    ## Cross validation test\n",
    "    scores = cross_val_score(tree_model,X_test,y_test,cv=4)\n",
    "    print(\"cross validate score for depth={0} \".format(max_depth),scores.mean())\n",
    "    \n",
    "    \n",
    "    if accuracy_tree > highest_accuracy_tree:\n",
    "        highest_accuracy_tree = accuracy_tree\n",
    "        best_accuracy_model_tree = temp_model_tree\n",
    "        best_value = max_depth\n",
    "\n",
    "print(\"Model resut with best depth={} without cross validation: \".format(best_value) , highest_accuracy_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_result(best_accuracy_model_tree, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
